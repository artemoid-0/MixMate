import os
import re
from fastapi import FastAPI
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from fastapi import Request
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from sentence_transformers import SentenceTransformer
from pinecone import Pinecone

# üîπ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI()

# –ü–æ–¥–∫–ª—é—á–∞–µ–º —à–∞–±–ª–æ–Ω—ã
templates = Jinja2Templates(directory="templates")

# üîπ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pinecone
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
pc = Pinecone(api_key=PINECONE_API_KEY)
index_name = "cocktail-index"  # –ò–º—è –∏–Ω–¥–µ–∫—Å–∞ —Å –∫–æ–∫—Ç–µ–π–ª—è–º–∏
INDEX_NAME_PREFERENCES = "user-preferences"
index = pc.Index(index_name)

# –ú–æ–¥–µ–ª—å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–æ–∫—Ç–µ–π–ª–µ–π –∏–∑ –±–∞–∑—ã Pinecone
def retrieve_relevant_cocktails(query, top_k=50):
    query_vector = embedding_model.encode([query]).tolist()  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–∞–ø—Ä–æ—Å –≤ —ç–º–±–µ–¥–¥–∏–Ω–≥
    results = index.query(vector=query_vector[0], top_k=top_k, include_metadata=True)  # –ü–æ–∏—Å–∫ –≤ –±–∞–∑–µ
    return [match["metadata"]["name"] for match in results["matches"]]


# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω–¥–µ–∫—Å—É –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π Pinecone
index_preferences = pc.Index(INDEX_NAME_PREFERENCES)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ Pinecone –ø–æ user_id
def retrieve_user_preferences(user_id):
    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–∞ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ user_id
    result = index_preferences.fetch(ids=[user_id])  # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ user_id

    if result["vectors"]:
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
        user_data = result["vectors"][user_id]
        return user_data["metadata"]
    else:
        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None –∏–ª–∏ –¥—Ä—É–≥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        return None


# –®–∞–±–ª–æ–Ω –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
def extract_preferences_from_query(query):
    # –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    like_pattern = r"(?:I like|I prefer|I love)\s+([a-zA-Z\s,]+)"
    dont_like_pattern = r"(?:I don't like|I hate)\s+([a-zA-Z\s,]+)"

    # –ò—â–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –ø–æ—Å–ª–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑
    like_matches = re.findall(like_pattern, query, re.IGNORECASE)
    dont_like_matches = re.findall(dont_like_pattern, query, re.IGNORECASE)

    likes = [item.strip() for sublist in like_matches for item in sublist.split(",")]
    dislikes = [item.strip() for sublist in dont_like_matches for item in sublist.split(",")]

    return likes, dislikes


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Pinecone
def update_user_preferences(user_id, likes, dislikes):
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –≤–∫–ª—é—á–∞—è –≤–µ–∫—Ç–æ—Ä
    result = index_preferences.fetch(ids=[user_id])  # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ user_id

    if result["vectors"]:  # –ï—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        user_data = result["vectors"][user_id]
        user_vector = user_data["values"]  # –í–µ–∫—Ç–æ—Ä –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –ø–æ–ª—è "values"
        current_likes = user_data["metadata"].get("likes", [])
        current_dislikes = user_data["metadata"].get("dislikes", [])
    else:
        # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –µ—â–µ –Ω–µ –∏–º–µ–µ—Ç –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –≤–µ–∫—Ç–æ—Ä (–º–æ–∂–Ω–æ –≤–∑—è—Ç—å –ø—É—Å—Ç–æ–π –≤–µ–∫—Ç–æ—Ä)
        user_vector = embedding_model.encode([""])  # –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–≤—É–º–µ—Ä–Ω—ã–π –º–∞—Å—Å–∏–≤ –≤ –æ–¥–Ω–æ–º–µ—Ä–Ω—ã–π –∏ –≤ —Ñ–æ—Ä–º–∞—Ç float
        user_vector = user_vector[0].tolist()  # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤—ã–π (–∏ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π) –≤–µ–∫—Ç–æ—Ä –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫
        user_vector = [float(val) for val in user_vector]  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–∞ - —ç—Ç–æ float

        current_likes = []
        current_dislikes = []

    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
    for item in likes:
        if item in current_dislikes:
            current_dislikes.remove(item)  # –£–±–∏—Ä–∞–µ–º –∏–∑ dislikes, –µ—Å–ª–∏ —ç—Ç–æ –≤ dislikes
        if item not in current_likes:
            current_likes.append(item)  # –î–æ–±–∞–≤–ª—è–µ–º –≤ likes, –µ—Å–ª–∏ –µ–≥–æ —Ç–∞–º –Ω–µ—Ç

    for item in dislikes:
        if item in current_likes:
            current_likes.remove(item)  # –£–±–∏—Ä–∞–µ–º –∏–∑ likes, –µ—Å–ª–∏ —ç—Ç–æ –≤ likes
        if item not in current_dislikes:
            current_dislikes.append(item)  # –î–æ–±–∞–≤–ª—è–µ–º –≤ dislikes, –µ—Å–ª–∏ –µ–≥–æ —Ç–∞–º –Ω–µ—Ç

    # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    metadata = {
        "likes": current_likes,
        "dislikes": current_dislikes
    }

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–ª–∏ –¥–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ Pinecone
    index_preferences.upsert(vectors=[(user_id, user_vector, metadata)])



# üîπ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ LLM (–Ω–∞–ø—Ä–∏–º–µ—Ä, OpenAI GPT)
llm = ChatOpenAI(model_name="gpt-4o-mini", api_key=os.getenv("OPENAI_API_KEY"))

# üîπ –®–∞–±–ª–æ–Ω –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
prompt_template = PromptTemplate(
    input_variables=["context", "query", "user_id", "preferences", "asked_about_suggestions"],
    template="""Use following context if possible:
    {context}

    User ID: {user_id}
    User's preferences: {preferences}
    Don't mention the word "context" or similar while answering.

    Answer the question: {query}
    """
)

# üîπ –ö–ª–∞—Å—Å –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è API
class QueryRequest(BaseModel):
    query: str
    user_id: str  # –î–æ–±–∞–≤–ª—è–µ–º ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    top_k: int = 50  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π


# üîπ –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –æ—Ç–¥–∞—á–∏ HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–∞—Ç–∞
@app.get("/", response_class=HTMLResponse)
async def get_chat_page(request: Request):
    return templates.TemplateResponse("chat.html", {"request": request})


# üîπ –≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
@app.post("/query")
async def query_cocktail(request: QueryRequest):
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–∫—Ç–µ–π–ª–∏
    relevant_cocktails = retrieve_relevant_cocktails(request.query, top_k=request.top_k)
    context = "\n".join(relevant_cocktails)  # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–∫—Ç–µ–π–ª–µ–π

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
    likes, dislikes = extract_preferences_from_query(request.query)

    # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Pinecone
    update_user_preferences(request.user_id, likes, dislikes)

    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ –µ–≥–æ ID
    preferences = retrieve_user_preferences(request.user_id)

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
    prompt = prompt_template.format(
        context=context,
        query=request.query,
        user_id=request.user_id,
        preferences=preferences
    )

    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç LLM
    response = llm.invoke(prompt)

    return {"response": response, "context": context, "preferences": preferences}
